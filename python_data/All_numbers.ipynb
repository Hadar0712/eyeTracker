{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import plotly.graph_objs as go\n",
    "from numpy import array, mean, std\n",
    "import biosignalsnotebooks as bsnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of directories (assuming they are in the current working directory)\n",
    "dirs = [f\"Subject {i}\" for i in range(1, 11)]\n",
    "\n",
    "for dir in dirs:\n",
    "    for i in range(1, 7):\n",
    "        # Load the processed file\n",
    "        filepath = os.path.join(dir, f\"movie_{i}_processed.csv\")\n",
    "        df = pd.read_csv(filepath)\n",
    "\n",
    "        # Calculate z-scores for the mentioned columns\n",
    "        columns_to_zscore = ['average_DisplayArea_y', 'average_DisplayArea_x', 'pupil Diameter_average']\n",
    "        for col in columns_to_zscore:\n",
    "            df[f'z_score_{col}'] = (df[col] - df[col].mean()) / df[col].std()\n",
    "\n",
    "        # Save the file with the new z-score columns\n",
    "        df.to_csv(filepath, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = [\n",
    "    'BVP_cleaned', 'EDA_cleaned', 'PZT_cleaned', 'z_score_pupil Diameter_average',\n",
    "    'z_score_average_DisplayArea_y',\n",
    "    'z_score_average_DisplayArea_x'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = [\n",
    "    'z_score_BVP', 'z_score_EDA', 'z_score_PZT',\n",
    "    'z_score_pupil Diameter_average',\n",
    "    'z_score_average_DisplayArea_y',\n",
    "    'z_score_average_DisplayArea_x'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and Store Data\n",
    "dirs = [f\"Subject {i}\" for i in range(1, 11)]\n",
    "movie_dataframes = {}\n",
    "for i in range(1, 7):\n",
    "    subject_dfs = {}\n",
    "    for dir in dirs:\n",
    "        filepath_opensignals = os.path.join(dir, f\"movie_{i}_opensignals.csv\")\n",
    "        filepath_processed = os.path.join(dir, f\"movie_{i}_processed.csv\")\n",
    "        \n",
    "        df_opensignals = pd.read_csv(filepath_opensignals)\n",
    "        df_processed = pd.read_csv(filepath_processed)\n",
    "        \n",
    "        merged_df = df_opensignals.join(df_processed, lsuffix='_opensignals', rsuffix='_processed')\n",
    "        sub_df = merged_df[columns_of_interest]\n",
    "        subject_dfs[dir] = sub_df\n",
    "\n",
    "    movie_dataframes[i] = subject_dfs\n",
    "movie_subject_correlations = {}\n",
    "\n",
    "for movie, subjects in movie_dataframes.items():\n",
    "    corr_dict = {}\n",
    "    for subject, df in subjects.items():\n",
    "        corr_dict[subject] = df.corr()\n",
    "    movie_subject_correlations[movie] = corr_dict\n",
    "\n",
    "overall_correlation_per_movie = {}\n",
    "\n",
    "for movie, correlations in movie_subject_correlations.items():\n",
    "    # This will average the correlations for the columns across all subjects\n",
    "    averaged_corrs = pd.DataFrame({subject: corr.mean() for subject, corr in correlations.items()})\n",
    "    overall_corr = averaged_corrs.corr()\n",
    "    overall_correlation_per_movie[movie] = overall_corr\n",
    "\n",
    "# Display the overall correlation between subjects for the first movie\n",
    "_ = overall_correlation_per_movie[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the overall correlation between subjects for all movies in one plot\n",
    "\n",
    "num_movies = len(overall_correlation_per_movie)\n",
    "fig, axes = plt.subplots(nrows=num_movies, figsize=(10, 8 * num_movies))\n",
    "\n",
    "for idx, (movie, correlation) in enumerate(overall_correlation_per_movie.items()):\n",
    "    ax = axes[idx]\n",
    "    sns.heatmap(correlation, annot=True, cmap='viridis', ax=ax)\n",
    "    ax.set_title(f\"Movie {movie}\")\n",
    "\n",
    "    # Add caption below each plot\n",
    "    ax.text(0.5, -0.3, f\"Parameters Tested: {', '.join(columns_of_interest)}\", \n",
    "            transform=ax.transAxes, fontsize=9, ha=\"center\", wrap=True)\n",
    "\n",
    "plt.tight_layout(pad=4.0)  # Increased padding to accommodate the caption\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select two groups of subjects\n",
    "all_subjects = dirs\n",
    "group_1 = random.sample(all_subjects, 5)\n",
    "group_2 = [subj for subj in all_subjects if subj not in group_1]\n",
    "\n",
    "\n",
    "def get_aggregated_data_for_group(group):\n",
    "    aggregated_data = {col: [] for col in columns_of_interest}\n",
    "    for movie_num, subjects_data in movie_dataframes.items():\n",
    "        for column in columns_of_interest:\n",
    "            group_data = [subjects_data[subject][column] for subject in group]\n",
    "            concatenated_data = pd.concat(group_data).groupby(level=0).mean()\n",
    "            aggregated_data[column].extend(concatenated_data)\n",
    "    return aggregated_data\n",
    "\n",
    "group_1_data = get_aggregated_data_for_group(group_1)\n",
    "group_2_data = get_aggregated_data_for_group(group_2)\n",
    "\n",
    "# Convert aggregated data for both groups into DataFrames\n",
    "df_group_1 = pd.DataFrame(group_1_data)\n",
    "df_group_2 = pd.DataFrame(group_2_data)\n",
    "\n",
    "# Calculate correlation matrices for both groups\n",
    "corr_matrix_group_1 = df_group_1.corr()\n",
    "corr_matrix_group_2 = df_group_2.corr()\n",
    "\n",
    "print(\"Correlation Matrix for Group 1:\")\n",
    "print(corr_matrix_group_1)\n",
    "print(\"\\nCorrelation Matrix for Group 2:\")\n",
    "print(corr_matrix_group_2)\n",
    "\n",
    "# Visualization\n",
    "movie_end_points = [0]\n",
    "for movie_num, subjects_data in movie_dataframes.items():\n",
    "    movie_end_points.append(movie_end_points[-1] + len(subjects_data[next(iter(subjects_data))]))\n",
    "movie_end_points = movie_end_points[:-1]\n",
    "\n",
    "for column in columns_of_interest:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=group_1_data[column], mode='lines', name=f'Group 1 - {column}'))\n",
    "    fig.add_trace(go.Scatter(y=group_2_data[column], mode='lines', name=f'Group 2 - {column}'))\n",
    "\n",
    "    for end in movie_end_points:\n",
    "        fig.add_shape(type=\"line\", x0=end, x1=end, y0=min(group_1_data[column] + group_2_data[column]),\n",
    "                      y1=max(group_1_data[column] + group_2_data[column]), line=dict(color=\"gray\", width=1, dash=\"dot\"))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Comparison for {column}',\n",
    "        xaxis_title='Sample Number',\n",
    "        yaxis_title='Average Value',\n",
    "        annotations=[\n",
    "            dict(x=0.5, y=-0.3, showarrow=False, text=\"Gray dashed lines indicate the end of each movie.\", xref=\"paper\", yref=\"paper\", font=dict(size=14)),\n",
    "            dict(x=0.5, y=1.2, showarrow=False, text=f\"Subjects in Group 1: {', '.join(group_1)}\", xref=\"paper\", yref=\"paper\", font=dict(size=14)),\n",
    "            dict(x=0.5, y=1.1, showarrow=False, text=f\"Subjects in Group 2: {', '.join(group_2)}\", xref=\"paper\", yref=\"paper\", font=dict(size=14))\n",
    "        ],\n",
    "        margin=dict(t=100, b=80)\n",
    "    )\n",
    "    # fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_with_zeros(a, target_length):\n",
    "    \"\"\"Pad array a with zeros to target_length.\"\"\"\n",
    "    return np.concatenate((a, np.zeros(target_length - len(a))))\n",
    "\n",
    "def get_padded_data(group_1_data, group_2_data):\n",
    "    max_len = max(len(group_1_data), len(group_2_data))\n",
    "    group_1_data = pad_with_zeros(group_1_data, max_len)\n",
    "    group_2_data = pad_with_zeros(group_2_data, max_len)\n",
    "    return group_1_data, group_2_data\n",
    "\n",
    "# Initialize a matrix to store correlation coefficients\n",
    "correlation_matrix = np.zeros((len(columns_of_interest), len(columns_of_interest)))\n",
    "\n",
    "# Calculate the correlation for each combination of columns\n",
    "for i, col_name_1 in enumerate(columns_of_interest):\n",
    "    for j, col_name_2 in enumerate(columns_of_interest):\n",
    "        group_1_data = np.nan_to_num(get_aggregated_data_for_group(group_1)[col_name_1])\n",
    "        group_2_data = np.nan_to_num(get_aggregated_data_for_group(group_2)[col_name_2])\n",
    "        \n",
    "        group_1_data, group_2_data = get_padded_data(group_1_data, group_2_data)\n",
    "        \n",
    "        # The [0, 1] index from np.corrcoef() gives the correlation between the two sets\n",
    "        correlation_matrix[i, j] = np.corrcoef(group_1_data, group_2_data)[0, 1]\n",
    "        \n",
    "\n",
    "# Plot the correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, ax=ax, cmap='coolwarm', vmin=0, vmax=1, square=True, \n",
    "            xticklabels=columns_of_interest, yticklabels=columns_of_interest)\n",
    "ax.set_title(\"Correlation Matrix - Group 1 vs. Group 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pad_with_zeros(a, target_length):\n",
    "    \"\"\"Pad array a with zeros to target_length.\"\"\"\n",
    "    return np.concatenate((a, np.zeros(target_length - len(a))))\n",
    "\n",
    "def get_padded_data(group_1_data, group_2_data):\n",
    "    max_len = max(len(group_1_data), len(group_2_data))\n",
    "    group_1_data = pad_with_zeros(group_1_data, max_len)\n",
    "    group_2_data = pad_with_zeros(group_2_data, max_len)\n",
    "    return group_1_data, group_2_data\n",
    "\n",
    "def is_empty_or_all_zeros(data):\n",
    "    \"\"\"Check if the array is empty or contains all zeros.\"\"\"\n",
    "    return len(data) == 0 or np.all(data == 0)\n",
    "\n",
    "def plot_correlation(group_1_data, group_2_data, data_name):\n",
    "    group_1_data, group_2_data = get_padded_data(group_1_data, group_2_data)\n",
    "    corr_matrix = np.corrcoef(group_1_data, group_2_data)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    sns.heatmap(corr_matrix, annot=True, ax=ax, cmap='coolwarm', vmin=-1, vmax=1, square=True)\n",
    "    ax.set_title(f\"{data_name} Correlation - Group 1 vs. Group 2\")\n",
    "    ax.set_xticks([0.5,1.5])\n",
    "    ax.set_yticks([0.5,1.5])\n",
    "    ax.set_xticklabels(['Group 1', 'Group 2'])\n",
    "    ax.set_yticklabels(['Group 1', 'Group 2'])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Fetch data for all combinations\n",
    "for col_name in columns_of_interest:\n",
    "    # Replace NaN values with 0 and convert to numpy array\n",
    "    group_1_data = [0 if x is np.nan else x for x in get_aggregated_data_for_group(group_1)[col_name]]\n",
    "    group_2_data = [0 if x is np.nan else x for x in get_aggregated_data_for_group(group_2)[col_name]]\n",
    "\n",
    "    if not (is_empty_or_all_zeros(group_1_data) or is_empty_or_all_zeros(group_2_data)):\n",
    "        plot_correlation(group_1_data, group_2_data, col_name)\n",
    "    else:\n",
    "        print(f\"Skipped plotting for column '{col_name}' as it's empty or contains only zeros.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sampling_rate = 300\n",
    "raw_signals = ['BVP', 'EDA', 'PZT']\n",
    "\n",
    "def plot_original_vs_cleaned_z_scores(original_z, cleaned_z, signal_name, subject_name, movie_num):\n",
    "    # Create a subplot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add the original z-scored plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=original_z, mode='lines', name='Original z-scored', line=dict(color='red'))\n",
    "    )\n",
    "    \n",
    "    # Add the cleaned z-scored plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(y=cleaned_z, mode='lines', name='Cleaned z-scored', line=dict(color='green'))\n",
    "    )\n",
    "\n",
    "    # Layout customization\n",
    "    fig.update_layout(\n",
    "        title=f'Subject {subject_name} - Movie {movie_num} - {signal_name}',\n",
    "        xaxis_title=\"Data Points\",\n",
    "        yaxis_title=\"Value\",\n",
    "        legend_title=\"Legend\"\n",
    "    )\n",
    "    \n",
    "    # Display the figure\n",
    "    fig.show()\n",
    "\n",
    "root_dir = os.getcwd()\n",
    "subject_dirs = [subj for subj in os.listdir(root_dir) if 'subject' in subj.lower()]\n",
    "\n",
    "for subject in subject_dirs:\n",
    "    subject_path = os.path.join(root_dir, subject)\n",
    "\n",
    "    for i in range(1, num_movies + 1):  # Assuming 'num_movies' is defined elsewhere\n",
    "        filepath_opensignals = os.path.join(subject_path, f\"movie_{i}_opensignals.csv\")\n",
    "        \n",
    "        if os.path.exists(filepath_opensignals):\n",
    "            df = pd.read_csv(filepath_opensignals)\n",
    "\n",
    "            for column in raw_signals:\n",
    "                signal = df[column].values\n",
    "\n",
    "                # Compute z-scores for original signals\n",
    "                original_z = (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "                # Cleaning process\n",
    "                signal_cleaned = signal - np.mean(signal)\n",
    "                \n",
    "                f_value = 1 if column in ['PZT', 'BVP'] else 0.5  # Set f value depending on the signal\n",
    "                signal_cleaned = bsnb.lowpass(signal_cleaned, f=f_value, order=3, fs=sampling_rate)\n",
    "\n",
    "                # Compute z-scores for cleaned signals\n",
    "                cleaned_z = (signal_cleaned - np.mean(signal_cleaned)) / np.std(signal_cleaned)\n",
    "\n",
    "                # Add cleaned data to dataframe\n",
    "                df[f\"{column}_cleaned\"] = cleaned_z\n",
    "\n",
    "                # Plot original vs cleaned z-scores for the current subject and movie\n",
    "                plot_original_vs_cleaned_z_scores(original_z, cleaned_z, column, subject, i)\n",
    "\n",
    "            # Save the updated dataframe back to the csv\n",
    "            df.to_csv(filepath_opensignals, index=False)\n",
    "            \n",
    "        else:\n",
    "            print(f\"File not found: {filepath_opensignals}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

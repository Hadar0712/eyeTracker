{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "001e181c-c726-4d96-8edf-6d040d109162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e4a4f-662a-46fd-b6b1-f760905af156",
   "metadata": {},
   "source": [
    "# Function to load MATLAB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75221908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadmat(filename):\n",
    "    def _check_keys(d):\n",
    "        for key in d:\n",
    "            if isinstance(d[key], spio.matlab.mio5_params.mat_struct):\n",
    "                d[key] = _todict(d[key])\n",
    "        return d\n",
    "\n",
    "    def _todict(matobj):\n",
    "        d = {}\n",
    "        for strg in matobj._fieldnames:\n",
    "            elem = matobj.__dict__[strg]\n",
    "            if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "                d[strg] = _todict(elem)\n",
    "            elif isinstance(elem, np.ndarray):\n",
    "                d[strg] = _tolist(elem)\n",
    "            else:\n",
    "                d[strg] = elem\n",
    "        return d\n",
    "\n",
    "    def _tolist(ndarray):\n",
    "        elem_list = []\n",
    "        for sub_elem in ndarray:\n",
    "            if isinstance(sub_elem, spio.matlab.mio5_params.mat_struct):\n",
    "                elem_list.append(_todict(sub_elem))\n",
    "            elif isinstance(sub_elem, np.ndarray):\n",
    "                elem_list.append(_tolist(sub_elem))\n",
    "            else:\n",
    "                elem_list.append(sub_elem)\n",
    "        return elem_list\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e7badcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_scores(dataframe, column_name):\n",
    "    # Calculate the mean and standard deviation of the specified column\n",
    "    mean = dataframe[column_name].mean()\n",
    "    std = dataframe[column_name].std()\n",
    "    \n",
    "    # Calculate the Z-scores for the specified column\n",
    "    z_scores = (dataframe[column_name] - mean) / std\n",
    "    \n",
    "    # Create a new DataFrame with the Z-scores added as a new column\n",
    "    result_df = dataframe.copy()\n",
    "    result_df['z_score_' + column_name] = z_scores\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b132a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_divided_dfs(divided_dfs, x_column, y_column, numeric_part, y_axis_name, min_value=None, max_value=None):\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    # Create a figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Define a time offset for each subset\n",
    "    time_offset = 0\n",
    "\n",
    "    # Iterate over the divided DataFrames\n",
    "    for i, df in enumerate(divided_dfs):\n",
    "        # Create a new filtered DataFrame based on the specified range\n",
    "        filtered_df = df.copy()\n",
    "        if min_value is not None:\n",
    "            filtered_df = filtered_df[filtered_df[y_column] >= min_value]\n",
    "        if max_value is not None:\n",
    "            filtered_df = filtered_df[filtered_df[y_column] <= max_value]\n",
    "\n",
    "        # Create a scatter trace for the current subset with the adjusted x-values\n",
    "        trace = go.Scatter(\n",
    "            x=filtered_df[x_column] + time_offset,\n",
    "            y=filtered_df[y_column],\n",
    "            mode='lines',\n",
    "            name=f'Movie {i + 1}'\n",
    "        )\n",
    "\n",
    "        # Add the trace to the figure\n",
    "        fig.add_trace(trace)\n",
    "\n",
    "        # Update the time offset for the next subset\n",
    "        time_offset += max(filtered_df[x_column])  # Use the maximum x_column value of the filtered DataFrame\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Time [sec]',\n",
    "        yaxis_title=y_axis_name,\n",
    "        title=y_column + ' Subject ' + numeric_part,\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "    fig.write_html(f'{y_column}_Subject_{numeric_part}.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cefcca",
   "metadata": {},
   "source": [
    "אתה צריך לשים רקאת הכתובת של התיקייה שאליה ישמרו כל הדברים\n",
    ",\n",
    "את הכתובת של קובץ טקסט שאנחנו מוציאים שמכיל את הזמנים והדגימות\n",
    "\n",
    "ואת הקובץ מטלב של הטובי "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3d67a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\hadar.yehuda\\\\Desktop\\\\אנדריי\\\\Name4\\\\Name4_run1.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\hadar.yehuda\\\\Desktop\\\\אנדריי\\\\Name4\\\\Name4_run1.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m output_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhadar.yehuda\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mאנדריי\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mName4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m file_path_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mhadar.yehuda\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mאנדריי\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mName4\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mName4.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mhadar.yehuda\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mאנדריי\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mName4\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mName4_run1.mat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 30\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     28\u001b[0m             elem_list\u001b[38;5;241m.\u001b[39mappend(sub_elem)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m elem_list\n\u001b[1;32m---> 30\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mspio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstruct_as_record\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msqueeze_me\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _check_keys(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:224\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03mLoad MATLAB file.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    223\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    225\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    226\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     f, opened \u001b[38;5;241m=\u001b[39m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappendmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m f\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\io\\matlab\\_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[1;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m appendmat \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_like\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     44\u001b[0m         file_like \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReader needs file name or open file-like object\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     49\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\hadar.yehuda\\\\Desktop\\\\אנדריי\\\\Name4\\\\Name4_run1.mat'"
     ]
    }
   ],
   "source": [
    "output_directory = r\"C:\\Users\\hadar.yehuda\\Desktop\\אנדריי\\Name4\"\n",
    "file_path_txt = r\"C:\\Users\\hadar.yehuda\\Desktop\\אנדריי\\Name4\\Name4.txt\"\n",
    "mat = loadmat(r\"C:\\Users\\hadar.yehuda\\Desktop\\אנדריי\\Name4\\Name4_run1.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_keyword = \"_converted\"\n",
    "file_list = os.listdir(output_directory)\n",
    "txt_files_with_keyword = [file for file in file_list if target_keyword in file and file.endswith('.txt')]\n",
    "matching_file_paths = [os.path.join(output_directory, file) for file in txt_files_with_keyword]\n",
    "file_path_plux =matching_file_paths[0]\n",
    "file_path_plux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parts = output_directory.split(\"\\\\\")\n",
    "last_part = path_parts[-1]\n",
    "numeric_part = ''.join(filter(str.isdigit, last_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba525a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path_txt, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "filtered_lines = [line.strip() for line in lines if \"Sample movie start\" in line or \"Sample movie end\" in line]\n",
    "filtered_lines_with_date = [line for line in filtered_lines if re.search(r'\\d{2}-\\w{3}-\\d{4}', line)]\n",
    "\n",
    "start_numbers = []\n",
    "end_numbers = []\n",
    "start_times = []\n",
    "end_times = []\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i].strip()\n",
    "\n",
    "    if \"The first BioSignals\" in line:\n",
    "        next_line = lines[i + 2]  # Get the line containing the number\n",
    "        number = float(next_line.strip().split()[0])  # Extract the number\n",
    "        start_numbers.append(number)\n",
    "\n",
    "        match = re.search(r'\\d{2}:\\d{2}:\\d{2}', lines[i - 1])\n",
    "        if match:\n",
    "            start_times.append(match.group())\n",
    "\n",
    "    elif \"The last BioSignals\" in line:\n",
    "        next_line = lines[i + 2]  # Get the line containing the number\n",
    "        number = float(next_line.strip().split()[0])  # Extract the number\n",
    "        end_numbers.append(number)\n",
    "\n",
    "        match = re.search(r'\\d{2}:\\d{2}:\\d{2}', lines[i - 1])\n",
    "        if match:\n",
    "            end_times.append(match.group())\n",
    "\n",
    "print(\"start_numbers =\", start_numbers)\n",
    "print(\"end_numbers =\", end_numbers)\n",
    "print(\"start_times =\", start_times)\n",
    "print(\"end_times =\", end_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34046400",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_systemTimeStamp = []\n",
    "end_systemTimeStamp = []\n",
    "start_times_t = []\n",
    "end_times_t = []\n",
    "\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "\n",
    "    if \"*Start* time :\" in line:\n",
    "        number = re.search(r': (\\d+)', line)\n",
    "        if number:\n",
    "            start_systemTimeStamp.append(number.group(1))\n",
    "\n",
    "        match = re.search(r'\\d{2}:\\d{2}:\\d{2}', line)\n",
    "        if match:\n",
    "            start_times_t.append(match.group())\n",
    "\n",
    "    if \"*End* time :\" in line:\n",
    "        number = re.search(r': (\\d+)', line)\n",
    "        if number:\n",
    "            end_systemTimeStamp.append(number.group(1))\n",
    "\n",
    "        match = re.search(r'\\d{2}:\\d{2}:\\d{2}', line)\n",
    "        if match:\n",
    "            end_times_t.append(match.group())\n",
    "\n",
    "print(\"Start System TimeStamp =\", start_systemTimeStamp)\n",
    "print(\"End System TimeStamp =\", end_systemTimeStamp)\n",
    "print(\"start_times =\", start_times_t)\n",
    "print(\"end_times =\", end_times_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee95a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_left = mat['dat']['data']['gaze']['left']['pupil']['diameter']\n",
    "data_right = mat['dat']['data']['gaze']['right']['pupil']['diameter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d905bec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DisplayArea_left_x = mat['dat']['data']['gaze']['left']['gazePoint']['onDisplayArea'][0]\n",
    "DisplayArea_right_x = mat['dat']['data']['gaze']['right']['gazePoint']['onDisplayArea'][0]\n",
    "DisplayArea_left_y = mat['dat']['data']['gaze']['left']['gazePoint']['onDisplayArea'][1]\n",
    "DisplayArea_right_y = mat['dat']['data']['gaze']['right']['gazePoint']['onDisplayArea'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = mat['dat']['data']['gaze']['systemTimeStamp']\n",
    "df_t = pd.DataFrame({'time_stamp' : time_stamp,\n",
    "                     'data_left':data_left ,'data_right':data_right,'DisplayArea_left_x':DisplayArea_left_x,\n",
    "                     'DisplayArea_right_x':DisplayArea_right_x,'DisplayArea_left_y':DisplayArea_left_y,\n",
    "                     'DisplayArea_right_y':DisplayArea_right_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = calculate_z_scores(df_t, 'data_left')\n",
    "df_t = calculate_z_scores(df_t, 'data_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc43b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_to_skip = 3  \n",
    "df = pd.read_csv(file_path_plux, delimiter=\"\\t\", skiprows=range(lines_to_skip), header=None)\n",
    "df = df.iloc[:, :5]\n",
    "df.columns = [\"sample_num\", \"Column2\", \"PZT\", \"BVP\" ,\"EDA\"]\n",
    "df = calculate_z_scores(df, 'PZT')\n",
    "df = calculate_z_scores(df, 'BVP')\n",
    "df = calculate_z_scores(df, 'EDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.to_csv(os.path.join(output_directory, 'reference_data.csv'), index=False)\n",
    "df.to_csv(os.path.join(output_directory, 'data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a9a7b5",
   "metadata": {},
   "source": [
    "כאן אתה צריך ללכת לקוד של המטלב שנקרא resample  \n",
    "לשנות את כתובות של התיקייה במטלב ולהריץ  \n",
    "data_file_path = \"C:\\Users\\hadar.yehuda\\Desktop\\אנדריי\\Name4\\data.csv\";\n",
    "reference_file_path = \"C:\\Users\\hadar.yehuda\\Desktop\\אנדריי\\Name4\\reference_data.csv\";\n",
    "אחרי שזה רץ אתה ממשיך את הקוד "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(output_directory, \"sorted_resampled_data.csv\")\n",
    "resampled_df = pd.read_csv(csv_path)\n",
    "sorted_resampled_df = resampled_df.sort_values(by='sample_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84963fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(sorted_resampled_df, df_t, left_index=True, right_index=True, how='inner')\n",
    "merged_df.to_csv(os.path.join(output_directory, 'all_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef190b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "divided_dfs = []\n",
    "resampled_df = sorted_resampled_df\n",
    "for i in range(len(start_numbers)):\n",
    "    start = start_numbers[i]\n",
    "    end = end_numbers[i]\n",
    "    subset_df = resampled_df[(resampled_df[\"sample_num\"] >= start) & (resampled_df[\"sample_num\"] <= end)]\n",
    "    subset_df = subset_df.reset_index(drop=True)  # Reset the index\n",
    "    divided_dfs.append(subset_df)\n",
    "\n",
    "#for i, df in enumerate(divided_dfs):\n",
    "#    print(f\"Subset {i+1}:\")\n",
    "#    print(df)\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f316f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the divided DataFrames\n",
    "for i, df in enumerate(divided_dfs):\n",
    "    start_time = pd.to_datetime(start_times[i], format=\"%H:%M:%S\")  # Convert start time to datetime object\n",
    "    end_time = pd.to_datetime(end_times[i], format=\"%H:%M:%S\")  # Convert end time to datetime object\n",
    "    \n",
    "    # Calculate the time interval between start and end time\n",
    "    time_interval = (end_time - start_time) / (len(df) - 1)\n",
    "    \n",
    "    # Calculate the time for each sample based on the violation count\n",
    "    sample_times = [start_time + idx * time_interval for idx in range(len(df))]\n",
    "    \n",
    "    # Calculate the time in seconds since the beginning of the interval\n",
    "    time_deltas = [(t - start_time).total_seconds() for t in sample_times]    \n",
    "    df['time_N'] = time_deltas\n",
    "    \n",
    "    # Print the modified DataFrame\n",
    "    print(f\"Subset {i+1}:\")\n",
    "    print(df)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec5d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over the divided DataFrames\n",
    "for i, df in enumerate(divided_dfs):\n",
    "    # Construct the CSV file name using the loop index\n",
    "    csv_file_name = f\"movie_{i+1}_opensignals.csv\"\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(os.path.join(output_directory, csv_file_name), index=False)\n",
    "\n",
    "    print(f\"Subset {i+1} saved to {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_divided_dfs(divided_dfs, 'time_N', 'z_score_EDA',numeric_part , 'EDA[uS]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_divided_dfs(divided_dfs, 'time_N', 'z_score_BVP',numeric_part , 'BVP[µV]',-1.5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb5dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_divided_dfs(divided_dfs, 'time_N', 'z_score_PZT', numeric_part, 'PZT[v]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7405b335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "divided_dfs_t = []\n",
    "\n",
    "for i in range(len(start_systemTimeStamp)):\n",
    "    start = int(start_systemTimeStamp[i])\n",
    "    end = int(end_systemTimeStamp[i])\n",
    "    subset_df = df_t[(df_t[\"time_stamp\"] >= start) & (df_t[\"time_stamp\"] <= end)]\n",
    "    subset_df = subset_df.reset_index(drop=True)  # Reset the index\n",
    "    divided_dfs_t.append(subset_df)\n",
    "\n",
    "for i, df in enumerate(divided_dfs_t):\n",
    "    print(f\"Subset {i+1}:\")\n",
    "    print(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d3215b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over the divided DataFrames\n",
    "for i, df in enumerate(divided_dfs_t):\n",
    "    start_time = pd.to_datetime(start_times[i], format=\"%H:%M:%S\")  # Convert start time to datetime object\n",
    "    end_time = pd.to_datetime(end_times[i], format=\"%H:%M:%S\")  # Convert end time to datetime object\n",
    "    \n",
    "    # Calculate the time interval between start and end time\n",
    "    time_interval = (end_time - start_time) / (len(df) - 1)\n",
    "    # Calculate the time for each sample based on the violation count\n",
    "    sample_times = [start_time + idx * time_interval for idx in range(len(df))]\n",
    "    \n",
    "    # Add the time column to the DataFrame and remove the date portion\n",
    "    time_deltas = [(t - start_time).total_seconds() for t in sample_times]    \n",
    "    df['time_N'] = time_deltas\n",
    "\n",
    "    df['pupil Diameter_average'] = df[['data_left', 'data_right']].mean(axis=1)\n",
    "    df['pupil Diameter'] = df[['z_score_data_left', 'z_score_data_right']].mean(axis=1)\n",
    "    df['average_DisplayArea_y'] = df[['DisplayArea_left_y', 'DisplayArea_right_y']].mean(axis=1)\n",
    "    df['average_DisplayArea_x'] = df[['DisplayArea_left_x', 'DisplayArea_right_x']].mean(axis=1)  \n",
    "    \n",
    "    # Print the modified DataFrame\n",
    "    print(f\"Subset {i+1}:\")\n",
    "    print(df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b04a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_divided_dfs(divided_dfs_t, 'time_N', 'pupil Diameter',numeric_part, 'pupil Diameter [pixels]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aabe863",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over the divided DataFrames\n",
    "for i, df in enumerate(divided_dfs_t):\n",
    "    # Construct the CSV file name using the loop index\n",
    "    csv_file_name = f\"movie_{i+1}_processed.csv\"\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(os.path.join(output_directory, csv_file_name), index=False)\n",
    "\n",
    "    print(f\"Subset {i+1} saved to {csv_file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
